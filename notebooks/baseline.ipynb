{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaa9cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.nn import GCNConv, global_add_pool, BatchNorm\n",
    "from torch_geometric.loader import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"‚úî Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc51e0b",
   "metadata": {},
   "source": [
    "# üì• Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9748f330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_949028/552373380.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(\"./../data/pyg_graphs.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Number of classes: 104\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.load(\"./../data/pyg_graphs.pt\")\n",
    "num_classes = len(set(int(data.y) for data in dataset))\n",
    "print(\"‚úî Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5096865",
   "metadata": {},
   "source": [
    "# üîÄ Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "n = len(dataset)\n",
    "train_dataset = dataset[:int(0.7 * n)]\n",
    "val_dataset   = dataset[int(0.7 * n):int(0.85 * n)]\n",
    "test_dataset  = dataset[int(0.85 * n):]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=256)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd2d6ac",
   "metadata": {},
   "source": [
    "# üß† GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3729317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNWithEmbeddings(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_node_types: int,\n",
    "                 num_spellings: int,\n",
    "                 hidden_dim: int = 128,\n",
    "                 num_classes: int = 104):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embeddings\n",
    "        self.type_embedding = nn.Embedding(num_node_types, hidden_dim)\n",
    "        self.spelling_embedding = nn.Embedding(num_spellings, hidden_dim)\n",
    "\n",
    "        # GCN stack\n",
    "        self.convs = nn.ModuleList([\n",
    "            GCNConv(hidden_dim * 2 + 2, hidden_dim),\n",
    "            GCNConv(hidden_dim, hidden_dim),\n",
    "            GCNConv(hidden_dim, hidden_dim),\n",
    "            GCNConv(hidden_dim, hidden_dim),\n",
    "        ])\n",
    "        self.norms = nn.ModuleList([\n",
    "            BatchNorm(hidden_dim) for _ in range(4)\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # x: [N, 4] = [type_id, spelling_id, is_op, is_lit]\n",
    "        type_id = x[:, 0]\n",
    "        spelling_id = x[:, 1]\n",
    "        flags = x[:, 2:].float()  # [is_operator, is_literal]\n",
    "\n",
    "        type_vec = self.type_embedding(type_id)\n",
    "        spell_vec = self.spelling_embedding(spelling_id)\n",
    "\n",
    "        node_vec = torch.cat([type_vec, spell_vec, flags], dim=1)\n",
    "\n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            node_vec = conv(node_vec, edge_index)\n",
    "            node_vec = norm(node_vec)\n",
    "            node_vec = F.relu(node_vec)\n",
    "            node_vec = self.dropout(node_vec)\n",
    "\n",
    "        graph_vec = global_add_pool(node_vec, batch)\n",
    "        x = F.relu(self.fc1(graph_vec))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "num_node_types = max(int(data.x[:, 0].max()) for data in dataset) + 1\n",
    "num_spellings  = max(int(data.x[:, 1].max()) for data in dataset) + 1\n",
    "model = GCNWithEmbeddings(num_node_types=num_node_types, num_spellings=num_spellings, hidden_dim=128, num_classes=num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9573f65",
   "metadata": {},
   "source": [
    "# üîÅ Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c04deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "        assert batch.y.max() < num_classes, f\"Invalid y: {batch.y.max()} ‚â• {num_classes}\"\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2d24f0",
   "metadata": {},
   "source": [
    "# üß™ √âvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c492fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == batch.y).sum())\n",
    "        total += batch.num_graphs\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22877f9",
   "metadata": {},
   "source": [
    "# üïπÔ∏è Early stopping params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53623cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc = 0.0\n",
    "patience = 100\n",
    "patience_counter = 0\n",
    "save_path = \"model_best.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb2836a",
   "metadata": {},
   "source": [
    "# üöÄ Training with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbcb6ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 4.8588 | Val Acc: 0.0000\n",
      "Epoch 002 | Loss: 4.3238 | Val Acc: 0.0000\n",
      "Epoch 003 | Loss: 4.3074 | Val Acc: 0.0000\n",
      "Epoch 004 | Loss: 4.3016 | Val Acc: 0.0000\n",
      "Epoch 005 | Loss: 4.2987 | Val Acc: 0.0000\n",
      "Epoch 006 | Loss: 4.2968 | Val Acc: 0.0000\n",
      "Epoch 007 | Loss: 4.2961 | Val Acc: 0.0000\n",
      "Epoch 008 | Loss: 4.2948 | Val Acc: 0.0000\n",
      "Epoch 009 | Loss: 4.2948 | Val Acc: 0.0000\n",
      "Epoch 010 | Loss: 4.2943 | Val Acc: 0.0000\n",
      "Epoch 011 | Loss: 4.2940 | Val Acc: 0.0000\n",
      "Epoch 012 | Loss: 4.2937 | Val Acc: 0.0000\n",
      "Epoch 013 | Loss: 4.2936 | Val Acc: 0.0000\n",
      "Epoch 014 | Loss: 4.2935 | Val Acc: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m10000\u001b[39m + \u001b[32m1\u001b[39m):\n\u001b[32m      2\u001b[39m     loss = train()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     val_acc = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m val_acc > best_val_acc:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(loader)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m      6\u001b[39m     batch = batch.to(device)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     pred = out.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m      9\u001b[39m     correct += \u001b[38;5;28mint\u001b[39m((pred == batch.y).sum())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/docs/algo_classifier/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/docs/algo_classifier/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mGCNWithEmbeddings.forward\u001b[39m\u001b[34m(self, x, edge_index, batch)\u001b[39m\n\u001b[32m     37\u001b[39m node_vec = torch.cat([type_vec, spell_vec, flags], dim=\u001b[32m1\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m conv, norm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.convs, \u001b[38;5;28mself\u001b[39m.norms):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     node_vec = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     node_vec = norm(node_vec)\n\u001b[32m     42\u001b[39m     node_vec = F.relu(node_vec)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/docs/algo_classifier/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/docs/algo_classifier/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/docs/algo_classifier/my_venv/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[39m, in \u001b[36mGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m    239\u001b[39m cache = \u001b[38;5;28mself\u001b[39m._cached_edge_index\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     edge_index, edge_weight = \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cached:\n\u001b[32m    245\u001b[39m         \u001b[38;5;28mself\u001b[39m._cached_edge_index = (edge_index, edge_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/docs/algo_classifier/my_venv/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:99\u001b[39m, in \u001b[36mgcn_norm\u001b[39m\u001b[34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[39m\n\u001b[32m     96\u001b[39m num_nodes = maybe_num_nodes(edge_index, num_nodes)\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     edge_index, edge_weight = \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     edge_weight = torch.ones((edge_index.size(\u001b[32m1\u001b[39m), ), dtype=dtype,\n\u001b[32m    104\u001b[39m                              device=edge_index.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/docs/algo_classifier/my_venv/lib/python3.11/site-packages/torch_geometric/utils/loop.py:652\u001b[39m, in \u001b[36madd_remaining_self_loops\u001b[39m\u001b[34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[39m\n\u001b[32m    648\u001b[39m     is_undirected = edge_index.is_undirected\n\u001b[32m    650\u001b[39m edge_index = edge_index[:, mask]\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_scripting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[32m    653\u001b[39m     edge_index._is_undirected = is_undirected\n\u001b[32m    655\u001b[39m edge_index = torch.cat([edge_index, loop_index], dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/docs/algo_classifier/my_venv/lib/python3.11/site-packages/torch/_jit_internal.py:103\u001b[39m, in \u001b[36mis_scripting\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m7\u001b[39m):\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBroadcastingList\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = BroadcastingList1\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_scripting\u001b[39m() -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03m    Function that returns True when in compilation and False otherwise. This\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m    is useful especially with the @unused decorator to leave code in your\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m \u001b[33;03m                return unsupported_linear_op(x)\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10000 + 1):\n",
    "    loss = train()\n",
    "    val_acc = evaluate(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"‚úÖ Model improved and saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"‚èπÔ∏è Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94ae7e",
   "metadata": {},
   "source": [
    "# üîç Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36172437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_777861/1140155854.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ Final Test Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "test_acc = evaluate(test_loader)\n",
    "print(f\"üèÅ Final Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f6b081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_949028/882744393.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(\"../data/pyg_graphs.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Val Acc: 0.0000\n",
      "Epoch 02 | Val Acc: 0.0000\n",
      "Epoch 03 | Val Acc: 0.0000\n",
      "Epoch 04 | Val Acc: 0.0000\n",
      "Epoch 05 | Val Acc: 0.0000\n",
      "Epoch 06 | Val Acc: 0.0000\n",
      "Epoch 07 | Val Acc: 0.0000\n",
      "Epoch 08 | Val Acc: 0.0000\n",
      "Epoch 09 | Val Acc: 0.0000\n",
      "Epoch 10 | Val Acc: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "dataset = torch.load(\"../data/pyg_graphs.pt\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Moyenne des features de chaque graphe\n",
    "X = torch.stack([data.x.float().mean(dim=0) for data in dataset])  # [N, 4]\n",
    "y = torch.tensor([int(data.y) for data in dataset])                # [N]\n",
    "\n",
    "# Split\n",
    "n = len(X)\n",
    "train_X, val_X = X[:int(0.8*n)], X[int(0.8*n):]\n",
    "train_y, val_y = y[:int(0.8*n)], y[int(0.8*n):]\n",
    "\n",
    "# Mini mod√®le MLP\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 104)\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Entra√Ænement rapide\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(train_X.to(device))\n",
    "    loss = criterion(out, train_y.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(val_X.to(device)).argmax(dim=1)\n",
    "        acc = (pred.cpu() == val_y).float().mean()\n",
    "        print(f\"Epoch {epoch+1:02d} | Val Acc: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
